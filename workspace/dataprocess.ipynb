{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "workspace_path=\"/home/hpclqz/share/project/04_TPBench/congestion_test/workspace\" \n",
    "time_stamp = \"-20250208_210330\"   \n",
    "time_stamp = ''        \n",
    "time_stamp = \"-20250212_125541\"   \n",
    "\n",
    "interleaved_path = os.path.join(workspace_path, f\"logs{time_stamp}-interleaved\")\n",
    "single_path = os.path.join(workspace_path, f\"logs{time_stamp}-single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plot\n",
    "\n",
    "\n",
    "class EnvironmentPara:\n",
    "    def __init__(self, task_type:str, node_num:int, node_list:list[str], start_time, end_time):\n",
    "        self.node_num:int = node_num\n",
    "        self.node_list = node_list\n",
    "        self.time_start = start_time\n",
    "        self.time_end = end_time\n",
    "        self.task_type = task_type\n",
    "        self.date_time = self.get_date_time(start_time, end_time)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}: {self.workload}\"\n",
    "\n",
    "    def get_date_time(self, start_time, end_time):\n",
    "        # start time: 20241227-230036\n",
    "        # end time: 20241227-230048\n",
    "        s_date = start_time.split('-')[0]\n",
    "        s_time = start_time.split('-')[1]\n",
    "        s_hour = int(s_time[:2])\n",
    "        s_min = int(s_time[2:4])\n",
    "        s_sec = int(s_time[4:])\n",
    "\n",
    "        e_date = end_time.split('-')[0]\n",
    "        e_time = end_time.split('-')[1]\n",
    "        e_hour = int(e_time[:2])\n",
    "        e_min = int(e_time[2:4])\n",
    "        e_sec = int(e_time[4:])\n",
    "\n",
    "        date = f\"{e_date[0:4]}-{e_date[4:6]}-{e_date[6:8]}\"\n",
    "        time = \"\"\n",
    "        if s_date == e_date:\n",
    "            if e_hour == s_hour:\n",
    "                if e_min == s_min:\n",
    "                    if s_sec <= 60 - e_sec:\n",
    "                        time = f\"{s_hour:02}:{s_min:02}:00\"\n",
    "                    else:\n",
    "                        time = f\"{s_hour:02}:{s_min:02}:00\"\n",
    "                else:\n",
    "                    time = f\"{s_hour:02}:{s_min:02}:00\"\n",
    "            else:\n",
    "                time = f\"{e_hour:02}:{e_min:02}:00\"\n",
    "        else:\n",
    "            time = f\"{e_hour:02}:{e_min:02}:00\"\n",
    "\n",
    "\n",
    "        return f\"{date} {time}\"\n",
    "\n",
    "class ProgramPara:\n",
    "    def __init__(self, lines:list[str]):\n",
    "       \n",
    "        self.vars = 0\n",
    "        self.iteration = 0\n",
    "        self.Time = 0\n",
    "        self.KBytesXchng_per_rank_max = 0.0\n",
    "        self.MB_per_sec_per_rank = 0.0\n",
    "\n",
    "        self.Msgs_per_sec = 0.0\n",
    "        self.MB_per_sec = 0.0\n",
    "\n",
    "        for i,line in enumerate(lines):\n",
    "            if  \"Message Size\" in line:\n",
    "                if line.split()[-1].isdigit():\n",
    "                    self.vars = int(line.split()[-1])\n",
    "                elif line.split()[-2].isdigit():\n",
    "                    self.vars = int(line.split()[-2])\n",
    "            elif \"Repeats\" in line:\n",
    "                self.iteration = int(line.split()[-1])\n",
    "            elif line.startswith(\"#   MsgSize        Time             KMsgs             MB           KMsg/S           MB/S\"):\n",
    "                # pingpang\n",
    "                line = lines[i+1]\n",
    "                self.Time = float(line.split()[1])\n",
    "                self.KMsgs = float(line.split()[2])\n",
    "                self.MB = float(line.split()[3])\n",
    "                self.KMsg_per_sec = float(line.split()[4])\n",
    "                self.MB_per_sec = float(line.split()[5])\n",
    "\n",
    "    def get_speed(self):\n",
    "        if self.MB_per_sec_per_rank:\n",
    "            return self.MB_per_sec_per_rank\n",
    "        elif self.MB_per_sec:\n",
    "            return self.MB_per_sec\n",
    "\n",
    "    def get_time(self):\n",
    "        return self.Time\n",
    "\n",
    "\n",
    "class Task:\n",
    "    def __init__(self, env_para: EnvironmentPara, program_para: ProgramPara):\n",
    "        self.kernel_name = 'pingpong'\n",
    "        self.env_para = env_para\n",
    "        self.program_para = program_para\n",
    "        self.date_time = self.env_para.date_time\n",
    "        self.task_type = self.env_para.task_type\n",
    "        self.time = self.program_para.get_time()\n",
    "        self.speed = self.program_para.get_speed()\n",
    "\n",
    "\n",
    "                    \n",
    "                            \n",
    "                            \n",
    "\n",
    "class Tasks:\n",
    "    speed_map = {\"incast\":\"MB_per_sec\", \"pingpong\":\"MB_per_sec\"}\n",
    "    headers = ['variables', 'node_num', 'node_list', 'date_time', 'task_type', 'total_time', 'MB/s']\n",
    "    types = [int, int, str, str, str, float, float]\n",
    "\n",
    "    def __init__(self, log_path:str, task_type:str, update_tasks=True):\n",
    "        self.tasks = [] \n",
    "        self.task_type = task_type\n",
    "        file_name_list = os.listdir(log_path)\n",
    "        self.data = pd.DataFrame(columns=Tasks.headers)\n",
    "\n",
    "        if update_tasks or os.path.exists(f'data{time_stamp}-{task_type}.csv') == False:\n",
    "            self.update_tasks_datas(file_name_list, log_path)\n",
    "        else:\n",
    "            self.data = pd.read_csv(f'data{time_stamp}-{task_type}.csv', dtype=dict(zip(Tasks.headers, Tasks.types)))\n",
    "    \n",
    "    def update_tasks_datas(self, file_name_list, log_path):\n",
    "        data_row = []\n",
    "        for file_name in file_name_list:\n",
    "            if file_name.endswith('.txt'):\n",
    "                file_path = os.path.join(log_path, file_name)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    node_num = 0\n",
    "                    node_infos:str = ''\n",
    "                    node_list = []\n",
    "                    task_type = ''\n",
    "                    \n",
    "                    start_time, end_time = '', ''\n",
    "                    start_line, end_line = 0, 0\n",
    "                    lines = f.readlines()\n",
    "                    for i,line in enumerate(lines):\n",
    "                        if line.startswith(\"Node Number:\"):\n",
    "                            node_num = int(line.split()[-1])\n",
    "                        elif line.startswith(\"Node List:\"):\n",
    "                            node_list = line.split()[-1]\n",
    "                        elif line.startswith(\"Task Type:\"):\n",
    "                            task_type = line.split()[-1]\n",
    "                        elif line.startswith(\"Start time:\"):\n",
    "                            tokens = line.split()\n",
    "                            start_time = tokens[-1]\n",
    "                            start_line = i + 1\n",
    "                        elif line.startswith(\"End time:\"):\n",
    "                            tokens = line.split()\n",
    "                            end_time = tokens[-1]\n",
    "                            end_line = i\n",
    "                            env_para = EnvironmentPara(task_type, node_num, node_list, start_time, end_time)\n",
    "                            program_para = ProgramPara(lines[start_line:end_line])\n",
    "                            task = Task(env_para, program_para)\n",
    "                            if program_para.vars > 0 and task.time > 0 and task.speed > 0:\n",
    "                                data_row.append([program_para.vars, node_num, node_list, env_para.date_time, \n",
    "                                                task_type, task.time, task.speed])\n",
    "                                \n",
    "                                self.tasks.append(task)\n",
    "                            start_time, end_time = '', ''\n",
    "                            start_line, end_line = 0, 0\n",
    "\n",
    "        self.data = pd.DataFrame(data_row, columns=Tasks.headers)\n",
    "        self.data.sort_values(['node_list', 'date_time', 'task_type', 'variables'], inplace=True)\n",
    "        # print(self.data)\n",
    "        self.data.to_csv(f'data{time_stamp}-{self.task_type}.csv', index=False)\n",
    "        \n",
    "    def plot_histogram(self, save_path:str):\n",
    "        variables_list = self.data['variables'].unique()\n",
    "        for variables in variables_list:\n",
    "            data_var = self.data[self.data['variables'] == variables]\n",
    "            title_base = f\"Histogram of {self.task_type} with {variables} Bytes\"\n",
    "            node_lists = data_var['node_list'].unique()\n",
    "            for node_list in node_lists:\n",
    "                data_node = data_var[data_var['node_list'] == node_list]\n",
    "                title = f\"{title_base}\\n{node_list}\"\n",
    "                file_name = f\"Histogram-{variables}-{node_list}-{self.task_type}\"\n",
    "                plot.plot_histogram(data=data_node, title=title, file_name=file_name, save_path=save_path, x='total_time')\n",
    "                plot.plot_histogram(data=data_node, title=title, file_name=file_name, save_path=save_path, x='MB/s')\n",
    "\n",
    "    def compare_histogram(self, task2:Task, save_path:str, title:str):\n",
    "        variables_list_1 = self.data['variables'].unique()\n",
    "        variables_list_2 = task2.data['variables'].unique()\n",
    "        variable_list = list(set(variables_list_1) & set(variables_list_2))\n",
    "        for variable in variable_list:\n",
    "            data_var_1 = self.data[self.data['variables'] == variable]\n",
    "            data_var_2 = task2.data[task2.data['variables'] == variable]\n",
    "            title_base = f\"Histogram of {self.task_type} with {variable} Bytes\"\n",
    "            node_lists_1 = data_var_1['node_list'].unique()\n",
    "            node_lists_2 = data_var_2['node_list'].unique()\n",
    "            node_list = list(set(node_lists_1) & set(node_lists_2))\n",
    "            for node in node_list:\n",
    "                data_node_1 = data_var_1[data_var_1['node_list'] == node]\n",
    "                data_node_2 = data_var_2[data_var_2['node_list'] == node]\n",
    "                title = f\"{title_base}\\n{node}\"\n",
    "                file_name = f\"{self.task_type}-{node}\"\n",
    "                plot.plot_histogram(data1=data_node_1, data2=data_node_2, title=title, file_name=file_name, save_path=save_path, x='total_time')\n",
    "                plot.plot_histogram(data1=data_node_1, data2=data_node_2, title=title, file_name=file_name, save_path=save_path, x='MB/s')\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "tasks_inter = Tasks(interleaved_path, task_type=\"interleaved\", update_tasks=False)\n",
    "tasks_single = Tasks(single_path, task_type=\"single\", update_tasks=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "workspace_path=\"/home/hpclqz/share/project/04_TPBench/congestion_test/workspace\"                      \n",
    "figure_path = os.path.join(workspace_path,f\"figures{time_stamp}-origin\")\n",
    "os.makedirs(figure_path, exist_ok=True)\n",
    "# tasks_inter.plot_histogram(figure_path)\n",
    "# tasks_single.plot_histogram(figure_path)\n",
    "# tasks_inter.compare_histogram(tasks_single, figure_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot\n",
    "\n",
    "class Tasks_Statistic():\n",
    "    hostfile_pair_list:list[tuple] = [(\"hostfile1\", \"hostfile2\"), (\"hostfile3\", \"hostfile4\"), (\"hostfile5\", \"hostfile6\")]\n",
    "    nodes_pair_list:list[tuple] = [(\"pi1,pi2\", \"pi3,pi4\"), (\"pi1,pi3\", \"pi2,pi4\"), (\"pi1,pi4\", \"pi2,pi3\"), (\"pi2,pi3\", \"pi1,pi4\"), (\"pi2,pi4\", \"pi1,pi3\"), (\"pi3,pi4\", \"pi1,pi2\")]\n",
    "    headers = ['nodes', 'variables', 'task_type', 'perf_type', 'average', 'std', 'max', 'min', '1%', '5%', '1%_avg', '5%_avg']\n",
    "    def __init__(self, tasks_inter:Tasks, tasks_single:Tasks, update_data=True):\n",
    "        self.data:pd.DataFrame = None\n",
    "        if update_data or os.path.exists(f'data{time_stamp}-statistic.csv') == False:\n",
    "            self.nodes_perf_statistic(tasks_inter)\n",
    "            self.nodes_perf_statistic(tasks_single)\n",
    "            self.data.sort_values(['perf_type', 'nodes', 'variables', 'task_type'], inplace=True)\n",
    "            self.data.to_csv(f'data{time_stamp}-statistic.csv', index=False)\n",
    "        else:\n",
    "            self.data = pd.read_csv(f'data{time_stamp}-statistic.csv')\n",
    "\n",
    "    def nodes_perf_statistic(self, tasks:Tasks):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        data_row = []\n",
    "        node_list = tasks.data['node_list'].unique()\n",
    "        for node in node_list:\n",
    "            data_node = tasks.data[tasks.data['node_list'] == node]\n",
    "            variables_list = data_node['variables'].unique()\n",
    "            for variables in variables_list:\n",
    "                data_var = data_node[data_node['variables'] == variables]\n",
    "                task_type_list = data_var['task_type'].unique()\n",
    "                for task_type in task_type_list:\n",
    "                    data_type = data_var[data_var['task_type'] == task_type]\n",
    "                    for perf_type in ['total_time', 'MB/s']:\n",
    "                        average = data_type[perf_type].mean()\n",
    "                        std = data_type[perf_type].std()\n",
    "                        max = data_type[perf_type].max()\n",
    "                        min = data_type[perf_type].min()\n",
    "                        if 'time' in perf_type:\n",
    "                            one_percent = data_type[perf_type].quantile(0.99)\n",
    "                            five_percent = data_type[perf_type].quantile(0.95)\n",
    "                            average_one_percent = data_type[data_type[perf_type] > one_percent][perf_type].mean()\n",
    "                            average_five_percent = data_type[data_type[perf_type] > five_percent][perf_type].mean()\n",
    "                        else:\n",
    "                            one_percent = data_type[perf_type].quantile(0.01)\n",
    "                            five_percent = data_type[perf_type].quantile(0.05)\n",
    "                            average_one_percent = data_type[data_type[perf_type] < one_percent][perf_type].mean()\n",
    "                            average_five_percent = data_type[data_type[perf_type] < five_percent][perf_type].mean()\n",
    "                        data_row.append([node, variables, task_type, perf_type, average, std, max, min, one_percent, five_percent, average_one_percent, average_five_percent])\n",
    "                    \n",
    "        if self.data is None:\n",
    "            self.data = pd.DataFrame(data_row, columns=Tasks_Statistic.headers)\n",
    "        else:\n",
    "            self.data = pd.concat([self.data, pd.DataFrame(data_row, columns=Tasks_Statistic.headers)])\n",
    "\n",
    "    def plot_statistic(self, save_path:str):\n",
    "        '''\n",
    "        绘制柱状图，每张图包含两对节点，柱状图的每个横轴是一个统计值：average,std,max,min,1%,5%,1%_avg,5%_avg，\n",
    "        一个横轴坐标包含两个柱，其中一个柱是interleaved的，另一个柱是single的（归一化展示，single柱值为1）\n",
    "        '''\n",
    "        stats = ['average','std', '1%_avg','5%_avg']\n",
    "        # For each statistic, create one figure that compares interleaved vs. single for a set of node pairs.\n",
    "        for vars in self.data['variables'].unique():\n",
    "            data_vars = self.data[self.data['variables'] == vars]\n",
    "            for stat in stats:\n",
    "                for perf_type in ['total_time', 'MB/s']:\n",
    "                    data_pt = data_vars[data_vars['perf_type'] == perf_type]\n",
    "                    title = f\"Comparison of {stat} for {vars} Bytes in {perf_type}\"\n",
    "                    file_name = f\"statistic-{vars}-{stat}-{perf_type.replace('/', 'per')}\"\n",
    "                    # data:pd.DataFrame, stat:str, title_format:str, save_path:str, file_name_format:str\n",
    "                    plot.plot_bar_with_discrete_x(data=data_pt, x='nodes', stat=stat, title=title, file_name=file_name, save_path=save_path)\n",
    "                    \n",
    "tasks_statistic = Tasks_Statistic(tasks_inter, tasks_single)\n",
    "figure_path = os.path.join(workspace_path, f\"figures{time_stamp}-statistic\")\n",
    "os.makedirs(figure_path, exist_ok=True)\n",
    "tasks_statistic.plot_statistic(figure_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task_Paired():\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.kernel_name:str = 'pingpong'\n",
    "        self.date_time:str = ''\n",
    "        self.variables:int = 0\n",
    "        self.node_pair1:str = ''\n",
    "        self.node_pair2:str = ''\n",
    "        self.nodepair1_inter:Task = None\n",
    "        self.nodepair2_inter:Task = None\n",
    "        self.nodepair1_single:Task = None\n",
    "        self.nodepair2_single:Task = None\n",
    "        self.speed_ave_inter = 0.0          # Average speed of interleaved node pair\n",
    "        self.speed_ave_single = 0.0         # Average speed of single node pair\n",
    "        self.time_ave_inter = 0.0\n",
    "        self.time_ave_single = 0.0\n",
    "\n",
    "    \n",
    "class Task_Paired_List():\n",
    "    hostfile_pair_list:list[tuple] = [(\"hostfile1\", \"hostfile2\"), (\"hostfile3\", \"hostfile4\"), (\"hostfile5\", \"hostfile6\")]\n",
    "    nodes_pair_list:list[tuple] = [(\"pi1,pi2\", \"pi3,pi4\"), (\"pi1,pi3\", \"pi2,pi4\"), (\"pi1,pi4\", \"pi2,pi3\")]\n",
    "    headers=['variables', 'date_time', 'node_pair1', 'node_pair2', 'time1_inter', 'time1_single', 'speed1_inter', 'speed1_single', 'time2_inter', 'time2_single', 'speed2_inter', 'speed2_single', 'time_ave_inter', 'time_ave_single', 'speed_ave_inter', 'speed_ave_single']\n",
    "    def __init__(self, log_path:str, update_tasks=True):\n",
    "        self.task_paired_list = []\n",
    "        self.data:pd.DataFrame = None\n",
    "        if update_tasks or os.path.exists(f'data{time_stamp}-paired.csv') == False:\n",
    "            self.update_tasks_datas(log_path)\n",
    "            self.data.sort_values(['variables', 'date_time', 'node_pair1', 'node_pair2'], inplace=True)\n",
    "            self.data.to_csv(f'data{time_stamp}-paired.csv', index=False)\n",
    "        else:\n",
    "            self.data = pd.read_csv(f'data{time_stamp}-paired.csv')\n",
    "\n",
    "    def update_tasks_datas(self, log_path):\n",
    "        log_interleaved_path = interleaved_path \n",
    "        log_single_path = single_path\n",
    "        file_inter_list = os.listdir(log_interleaved_path)\n",
    "        file_single_list = os.listdir(log_single_path)\n",
    "        time_list_dict:dict[str, list] = {}\n",
    "        for file_name in file_inter_list:\n",
    "            if file_name.endswith('.txt'):\n",
    "                hostfile= file_name.split('-')[1]\n",
    "                date=file_name.split('-')[2]\n",
    "                time=file_name.split('-')[3].split('.')[0]\n",
    "                data_time=f\"{date}-{time}\"\n",
    "                if hostfile not in time_list_dict:\n",
    "                    time_list_dict[hostfile] = []\n",
    "                if data_time not in time_list_dict[hostfile]:\n",
    "                    time_list_dict[hostfile].append(data_time)\n",
    "        for i, hostfile_pair in enumerate(Task_Paired_List.hostfile_pair_list):\n",
    "            nodes_pair = Task_Paired_List.nodes_pair_list[i]\n",
    "            time_list = time_list_dict[hostfile_pair[0]]\n",
    "            \n",
    "            data_row = []\n",
    "            for time in time_list:\n",
    "                file1_inter_path=os.path.join(log_interleaved_path,f\"log-{hostfile_pair[0]}-{time}.txt\")\n",
    "                file2_inter_path=os.path.join(log_interleaved_path,f\"log-{hostfile_pair[1]}-{time}.txt\")\n",
    "                file1_single_path=os.path.join(log_single_path,f\"log-{hostfile_pair[0]}-{time}.txt\")\n",
    "                file2_single_path=os.path.join(log_single_path,f\"log-{hostfile_pair[1]}-{time}.txt\")\n",
    "                if os.path.exists(file1_inter_path) == False or os.path.exists(file2_inter_path) == False or os.path.exists(file1_single_path) == False or os.path.exists(file2_single_path) == False:\n",
    "                    print(f\"Warning: Does {file1_inter_path} exit? {os.path.exists(file1_inter_path)}\")\n",
    "                    print(f\"Warning: Does {file2_inter_path} exit? {os.path.exists(file2_inter_path)}\")\n",
    "                    print(f\"Warning: Does {file1_single_path} exit? {os.path.exists(file1_single_path)}\")\n",
    "                    print(f\"Warning: Does {file2_single_path} exit? {os.path.exists(file2_single_path)}\")\n",
    "                    continue\n",
    "                file_list = [file1_inter_path, file2_inter_path, file1_single_path, file2_single_path]\n",
    "                file_task_dict:dict[str, list[Task]] = {}\n",
    "                for file in file_list:\n",
    "                    with open(file, 'r') as f:\n",
    "                        node_num = 0\n",
    "                        node_infos:str = ''\n",
    "                        node_list = []\n",
    "                        task_type = ''\n",
    "                        start_time, end_time = '', ''\n",
    "                        start_line, end_line = 0, 0\n",
    "                        lines = f.readlines()\n",
    "                        for i,line in enumerate(lines):\n",
    "                            if line.startswith(\"Node Number:\"):\n",
    "                                node_num = int(line.split()[-1])\n",
    "                            elif line.startswith(\"Node List:\"):\n",
    "                                node_list = line.split()[-1]\n",
    "                            elif line.startswith(\"Task Type:\"):\n",
    "                                task_type = line.split()[-1]\n",
    "                            elif line.startswith(\"Start time:\"):\n",
    "                                tokens = line.split()\n",
    "                                start_time = tokens[-1]\n",
    "                                start_line = i + 1\n",
    "                            elif line.startswith(\"End time:\"):\n",
    "                                tokens = line.split()\n",
    "                                end_time = tokens[-1]\n",
    "                                end_line = i\n",
    "                                env_para = EnvironmentPara(task_type, node_num, node_list, start_time, end_time)\n",
    "                                program_para = ProgramPara(lines[start_line:end_line])\n",
    "                                task = Task(env_para, program_para)\n",
    "                                if program_para.vars > 0 and task.time > 0 and task.speed > 0:\n",
    "                                    if file not in file_task_dict:\n",
    "                                        file_task_dict[file] = []\n",
    "                                    file_task_dict[file].append(task)\n",
    "                                start_time, end_time = '', ''\n",
    "                                start_line, end_line = 0, 0\n",
    "                if len(file_task_dict) != 4:\n",
    "                    print(f\"Warning: file_task_dict is not 4\")\n",
    "                    print(f\"Warning: {file1_inter_path} {file2_inter_path} {file1_single_path} {file2_single_path}\")\n",
    "                    continue\n",
    "                if len(file_task_dict[file1_inter_path]) == len(file_task_dict[file2_inter_path]) and len(file_task_dict[file1_inter_path]) == len(file_task_dict[file1_single_path]) and len(file_task_dict[file1_inter_path]) == len(file_task_dict[file2_single_path]):\n",
    "                    for i in range(len(file_task_dict[file1_inter_path])):\n",
    "                        task_paired = Task_Paired()\n",
    "                        task_paired.variables = file_task_dict[file1_inter_path][i].program_para.vars\n",
    "                        task_paired.node_pair1 = nodes_pair[0]\n",
    "                        task_paired.node_pair2 = nodes_pair[1]\n",
    "                        task_paired.date_time = file_task_dict[file1_inter_path][i].date_time\n",
    "                        task_paired.nodepair1_inter = file_task_dict[file1_inter_path][i]\n",
    "                        task_paired.nodepair2_inter = file_task_dict[file2_inter_path][i]\n",
    "                        task_paired.nodepair1_single = file_task_dict[file1_single_path][i]\n",
    "                        task_paired.nodepair2_single = file_task_dict[file2_single_path][i]\n",
    "                        task_paired.speed_ave_inter = (task_paired.nodepair1_inter.speed + task_paired.nodepair2_inter.speed) / 2\n",
    "                        task_paired.speed_ave_single = (task_paired.nodepair1_single.speed + task_paired.nodepair2_single.speed) / 2\n",
    "                        task_paired.time_ave_inter = (task_paired.nodepair1_inter.time + task_paired.nodepair2_inter.time) / 2\n",
    "                        task_paired.time_ave_single = (task_paired.nodepair1_single.time + task_paired.nodepair2_single.time) / 2\n",
    "                        self.task_paired_list.append(task_paired)\n",
    "                        data_row.append([task_paired.variables, task_paired.date_time, task_paired.node_pair1, task_paired.node_pair2, task_paired.nodepair1_inter.time, task_paired.nodepair1_single.time, task_paired.nodepair1_inter.speed, task_paired.nodepair1_single.speed, task_paired.nodepair2_inter.time, task_paired.nodepair2_single.time, task_paired.nodepair2_inter.speed, task_paired.nodepair2_single.speed, task_paired.time_ave_inter, task_paired.time_ave_single, task_paired.speed_ave_inter, task_paired.speed_ave_single])\n",
    "                else:\n",
    "                    print(f\"Warning: file_task_dict is not equal\")\n",
    "                    print(f\"Warning: {file1_inter_path} {file2_inter_path} {file1_single_path} {file2_single_path}\")\n",
    "                    print(f\"len(file_task_dict[file1_inter_path]) = {len(file_task_dict[file1_inter_path])}\")\n",
    "                    print(f\"len(file_task_dict[file2_inter_path]) = {len(file_task_dict[file2_inter_path])}\")\n",
    "                    print(f\"len(file_task_dict[file1_single_path]) = {len(file_task_dict[file1_single_path])}\")\n",
    "                    print(f\"len(file_task_dict[file2_single_path]) = {len(file_task_dict[file2_single_path])}\")\n",
    "            if self.data is None:\n",
    "                self.data = pd.DataFrame(data_row, columns=Task_Paired_List.headers)\n",
    "            else:\n",
    "                self.data = pd.concat([self.data, pd.DataFrame(data_row, columns=Task_Paired_List.headers)])\n",
    "\n",
    "    def plot_histogram(self, save_path:str):\n",
    "        variables_list = self.data['variables'].unique()\n",
    "        for variables in variables_list:\n",
    "            data_var = self.data[self.data['variables'] == variables]\n",
    "            for node_pair in Task_Paired_List.nodes_pair_list:\n",
    "                data_node = data_var[(data_var['node_pair1'] == node_pair[0]) & (data_var['node_pair2'] == node_pair[1])]\n",
    "                if data_node.shape[0] == 0:\n",
    "                    continue\n",
    "                title_base = f\"Histogram with {variables} Bytes\"\n",
    "                title = f\"{title_base}\\n{node_pair[0]} & {node_pair[1]}\"\n",
    "                file_name = f\"Histogram-{variables}-{node_pair[0]}_{node_pair[1]}\"\n",
    "                plot.plot_histogram(data=data_node, title=title, file_name=file_name, save_path=save_path, x='time_ave_inter')\n",
    "                plot.plot_histogram(data=data_node, title=title, file_name=file_name, save_path=save_path, x='time_ave_single')\n",
    "                plot.plot_histogram(data=data_node, title=title, file_name=file_name, save_path=save_path, x='speed_ave_inter')\n",
    "                plot.plot_histogram(data=data_node, title=title, file_name=file_name, save_path=save_path, x='speed_ave_single')\n",
    "            \n",
    "figure_path = os.path.join(workspace_path, f\"figures{time_stamp}-paired\")\n",
    "os.makedirs(figure_path, exist_ok=True)\n",
    "task_paired_list = Task_Paired_List(workspace_path, update_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_paired_list.plot_histogram(figure_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task_Paired_Statistic():\n",
    "    hostfile_pair_list:list[tuple] = [(\"hostfile1\", \"hostfile2\"), (\"hostfile3\", \"hostfile4\"), (\"hostfile5\", \"hostfile6\")]\n",
    "    nodes_pair_list:list[tuple] = [(\"pi1,pi2\", \"pi3,pi4\"), (\"pi1,pi3\", \"pi2,pi4\"), (\"pi1,pi4\", \"pi2,pi3\")]\n",
    "    headers = ['node_pair1', 'node_pair2', 'variables', 'task_type', 'perf_type', 'average', 'std', 'max', 'min', '1%', '5%', '1%_avg', '5%_avg']\n",
    "    def __init__(self, task_paired_list:Task_Paired_List, update_data=True):\n",
    "        self.data:pd.DataFrame = None\n",
    "        if update_data or os.path.exists(f'data{time_stamp}-paired-statistic.csv') == False:\n",
    "            self.nodes_perf_statistic(task_paired_list)\n",
    "            self.data.sort_values(['perf_type', 'node_pair1', 'variables', 'task_type'], inplace=True)\n",
    "            self.data.to_csv(f'data{time_stamp}-paired-statistic.csv', index=False)\n",
    "        else:\n",
    "            self.data = pd.read_csv(f'data{time_stamp}-paired-statistic.csv')\n",
    "\n",
    "    def nodes_perf_statistic(self, task_paired_list:Task_Paired_List):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        data_row = []\n",
    "        for node_pair in Task_Paired_Statistic.nodes_pair_list:\n",
    "            data_node = task_paired_list.data[(task_paired_list.data['node_pair1'] == node_pair[0]) & (task_paired_list.data['node_pair2'] == node_pair[1])]\n",
    "            variables_list = data_node['variables'].unique()\n",
    "            for variables in variables_list:\n",
    "                data_var = data_node[data_node['variables'] == variables]\n",
    "                for res_type in ['time_ave_inter', 'time_ave_single', 'speed_ave_inter', 'speed_ave_single']:\n",
    "                    task_type = 'interleaved' if 'inter' in res_type else 'single'\n",
    "                    perf_type = 'total_time' if 'time' in res_type else 'MB/s'\n",
    "                    average = data_var[res_type].mean()\n",
    "                    std = data_var[res_type].std()\n",
    "                    max = data_var[res_type].max()\n",
    "                    min = data_var[res_type].min()\n",
    "                    if 'time' in res_type:\n",
    "                        one_percent = data_var[res_type].quantile(0.99)\n",
    "                        five_percent = data_var[res_type].quantile(0.95)\n",
    "                        average_one_percent = data_var[data_var[res_type] > one_percent][res_type].mean()\n",
    "                        average_five_percent = data_var[data_var[res_type] > five_percent][res_type].mean()\n",
    "                    else:\n",
    "                        one_percent = data_var[res_type].quantile(0.01)\n",
    "                        five_percent = data_var[res_type].quantile(0.05)\n",
    "                        average_one_percent = data_var[data_var[res_type] < one_percent][res_type].mean()\n",
    "                        average_five_percent = data_var[data_var[res_type] < five_percent][res_type].mean()\n",
    "                    data_row.append([node_pair[0], node_pair[1], variables, task_type, perf_type, average, std, max, min, one_percent, five_percent, average_one_percent, average_five_percent])\n",
    "                    \n",
    "        if self.data is None:\n",
    "            self.data = pd.DataFrame(data_row, columns=Task_Paired_Statistic.headers)\n",
    "        else:\n",
    "            self.data = pd.concat([self.data, pd.DataFrame(data_row, columns=Task_Paired_Statistic.headers)])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def plot_statistic(self, save_path:str):\n",
    "        '''\n",
    "        绘制柱状图，每张图包含两对节点，柱状图的每个横轴是一个统计值：average,std,max,min,1%,5%,1%_avg,5%_avg，\n",
    "        一个横轴坐标包含两个柱，其中一个柱是interleaved的，另一个柱是single的（归一化展示，single柱值为1）\n",
    "        '''\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        def plot_two_pairs_bar(ax, stats, data, perf_type, offset, color, task_type):\n",
    "            values = []\n",
    "            single_row = None\n",
    "            # For interleaved, first get the corresponding single row for normalization.\n",
    "            if task_type == 'interleaved':\n",
    "                single_query = data[\n",
    "                    (data['task_type'] == 'single') &\n",
    "                    (data['perf_type'] == perf_type)\n",
    "                ]\n",
    "                if not single_query.empty:\n",
    "                    single_row = single_query.iloc[0]\n",
    "            for stat in stats:\n",
    "                cur_query = data[\n",
    "                    (data['task_type'] == task_type) &\n",
    "                    (data['perf_type'] == perf_type)\n",
    "                ]\n",
    "                if cur_query.shape[0] > 0:\n",
    "                    cur_val = cur_query[stat].iloc[0]\n",
    "                    if task_type == 'single':\n",
    "                        norm_val = 1\n",
    "                    else:\n",
    "                        if single_row is not None and single_row[stat] != 0:\n",
    "                            norm_val = cur_val / single_row[stat]\n",
    "                        else:\n",
    "                            norm_val = 0\n",
    "                else:\n",
    "                    norm_val = 0\n",
    "                values.append(norm_val)\n",
    "            x = range(len(stats))\n",
    "            ax.bar([p + offset for p in x], values, width=0.15, label=f\"{task_type}\", color=color)\n",
    "\n",
    "\n",
    "        stats = ['average','std','max','min','1%','5%','1%_avg','5%_avg']\n",
    "        for variable in self.data['variables'].unique():\n",
    "            data_var = self.data[self.data['variables'] == variable]\n",
    "            task_type_list = data_var['task_type'].unique()\n",
    "            if len(task_type_list) != 2:\n",
    "                continue\n",
    "            for node_pair in Task_Paired_Statistic.nodes_pair_list:\n",
    "                data_node_pair = data_var[(data_var['node_pair1'] == node_pair[0]) & (data_var['node_pair2'] == node_pair[1])]\n",
    "                if data_node_pair.shape[0] == 0:\n",
    "                    continue\n",
    "                for perf_type in ['total_time', 'MB/s']:\n",
    "                    fig, ax = plt.subplots(figsize=(8,4))\n",
    "                    plot_two_pairs_bar(ax, stats, data_node_pair, perf_type, -0.03, 'orange', 'single')\n",
    "                    plot_two_pairs_bar(ax, stats, data_node_pair, perf_type, 0.12, 'blue', 'interleaved')\n",
    "                    ax.set_xticks(range(len(stats)))\n",
    "                    # ax.set_yscale('log', base=10)\n",
    "                    ax.set_xticklabels(stats, rotation=20)\n",
    "                    ax.set_title(f\"{node_pair} {variable} Bytes {perf_type}\")\n",
    "                    ax.legend()\n",
    "                    file_name = f\"Paired_Statistic-{variable}-{perf_type.replace('/', 'per')}-{node_pair}.png\"\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(os.path.join(save_path, file_name))\n",
    "                    plt.close()\n",
    "\n",
    "    def plot_statistic_nodes(self, save_path:str):\n",
    "        '''\n",
    "        绘制柱状图，每张图包含两对节点，柱状图的每个横轴是一个统计值：average,std,max,min,1%,5%,1%_avg,5%_avg，\n",
    "        一个横轴坐标包含两个柱，其中一个柱是interleaved的，另一个柱是single的（归一化展示，single柱值为1）\n",
    "        '''\n",
    "        import matplotlib.pyplot as plt\n",
    "        stats = ['average','std', '1%_avg','5%_avg']\n",
    "        # For each statistic, create one figure that compares interleaved vs. single for a set of node pairs.\n",
    "        for vars in self.data['variables'].unique():\n",
    "            data_vars = self.data[self.data['variables'] == vars]\n",
    "            for stat in stats:\n",
    "                for perf_type in ['total_time', 'MB/s']:\n",
    "                    data_pt = data_vars[data_vars['perf_type'] == perf_type]\n",
    "                    title = f\"Comparison of {stat} for {vars} Bytes in {perf_type}\"\n",
    "                    file_name = f\"statistic-{vars}-{stat}-{perf_type.replace('/', 'per')}.png\"\n",
    "                    plot.plot_bar_with_discrete_x(data=data_pt, x='node_pair1', stat=stat, title=title, file_name=file_name, save_path=save_path)\n",
    "\n",
    "                \n",
    "tasks_paired_statistic = Task_Paired_Statistic(task_paired_list, update_data=True)\n",
    "figure_path = os.path.join(workspace_path, f\"figures{time_stamp}-paired-statistic\")\n",
    "os.makedirs(figure_path, exist_ok=True)\n",
    "# tasks_paired_statistic.plot_statistic(figure_path)\n",
    "tasks_paired_statistic.plot_statistic_nodes(figure_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
